{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers import merge, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3344, 244, 244)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Band 1: blue; Band 2: green; Band 3: red; Band 4: nir\n",
    "I = np.load(os.path.join('../data/Training.npy'))\n",
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3344, 244, 244)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = np.load('../data/Targets.npy')\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 0 signifies nodata\n",
    "classes = np.unique(T.flatten())\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3344, 244, 244)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.float32(I)\n",
    "X[X>10000] = 10000\n",
    "X = X / 10000.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3344, 244, 244, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.rollaxis(X, 0, 4)\n",
    "xshape = X.shape\n",
    "print(xshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12655076384544373 0.016980711370706558\n",
      "0.09710454940795898 0.016959035769104958\n",
      "0.07182221114635468 0.023930516093969345\n",
      "0.17956602573394775 0.12075547128915787\n"
     ]
    }
   ],
   "source": [
    "mu = np.zeros((4,))\n",
    "std = np.zeros((4,))\n",
    "for q in range(X.shape[3]):\n",
    "    tmp = copy.copy(X[:, :, :, q])\n",
    "    tmp = tmp.flatten()\n",
    "    mu[q] = tmp[tmp>0].mean()\n",
    "    std[q] = tmp[tmp>0].std()\n",
    "    print(mu[q], std[q])\n",
    "    tmp[tmp>0] = (tmp[tmp>0] - mu[q]) / std[q]\n",
    "    X[:, :, :, q] = tmp.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data quality check is to delete images that \n",
    "    - all image belongs to one class. These are often either large water bodies or distorted images\n",
    "    - Images that have less then 3 classes, which are again distorted imaages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr=[]\n",
    "for i in range(T.shape[0]):\n",
    "    if np.std(T[i,:,:])==0 or np.unique(T[i,:,:]).size<3:\n",
    "        arr.append(i)\n",
    "        \n",
    "T=np.delete(T,arr,0)\n",
    "X=np.delete(X,arr,0)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2702, 244, 244, 9)\n"
     ]
    }
   ],
   "source": [
    "Y = np.zeros(T.shape +  (len(classes),), dtype=np.float32)\n",
    "for q in range(len(classes)):\n",
    "    tmp = Y[:,:,:,q]\n",
    "    tmp[T==q] = 1\n",
    "    Y[:,:,:,q] = tmp\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/X', X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/Y', Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.load(os.path.join('../data/X.npy'))\n",
    "Y1=np.load(os.path.join('../data/Y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1= X1[:,:128,:128,:]\n",
    "Y1= Y1[:,:128,:128,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2702, 128, 128, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2702, 128, 128, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-6764b0b13c02>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-6764b0b13c02>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    def identity_block(input_tensor, kernel_size, filters, stage, block):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "\n",
    "# Source:\n",
    "# https://github.com/fchollet/deep-learning-models/blob/master/resnet50.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block,\n",
    "               strides=(2, 2)):\n",
    "    \"\"\"conv_block is the block that has a conv layer at shortcut\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: defualt 3, the kernel size of middle conv layer at\n",
    "                     main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with\n",
    "    strides=(2,2) and the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=strides,\n",
    "               name=conv_name_base + '2a')(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING,\n",
    "               padding='same', name=conv_name_base + '2b')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=conv_name_base + '2c')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "                      strides=strides, name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_resnet50_encoder(input_height=224,  input_width=224,\n",
    "                         pretrained='imagenet',\n",
    "                         include_top=True, weights='imagenet',\n",
    "                         input_tensor=None, input_shape=None,\n",
    "                         pooling=None,\n",
    "                         classes=1000):\n",
    "\n",
    "    assert input_height % 32 == 0\n",
    "    assert input_width % 32 == 0\n",
    "    inputs = keras.Input(shape=img_size )\n",
    "  \n",
    "    x = ZeroPadding2D((3, 3), data_format=IMAGE_ORDERING)(img_input)\n",
    "    x = Conv2D(64, (7, 7), data_format=IMAGE_ORDERING,\n",
    "               strides=(2, 2), name='conv1')(x)\n",
    "    f1 = x\n",
    "\n",
    "    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), data_format=IMAGE_ORDERING, strides=(2, 2))(x)\n",
    "\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
    "    f2 = one_side_pad(x)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
    "    f3 = x\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    f4 = x\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    f5 = x\n",
    "\n",
    "    x = AveragePooling2D(\n",
    "        (7, 7), data_format=IMAGE_ORDERING, name='avg_pool')(x)\n",
    "    # f6 = x\n",
    "\n",
    "    if pretrained == 'imagenet':\n",
    "        weights_path = keras.utils.get_file(\n",
    "            pretrained_url.split(\"/\")[-1], pretrained_url)\n",
    "        Model(img_input, x).load_weights(weights_path)\n",
    "\n",
    "    return img_input, [f1, f2, f3, f4, f5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_resnet50_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "epochs = 100\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"../checkpoints/test.h5\", save_best_only=True)\n",
    "]\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1081/1081 [==============================] - 24s 22ms/step - loss: 10.6362 - val_loss: 13.6665\n",
      "Epoch 2/100\n",
      "1081/1081 [==============================] - 21s 20ms/step - loss: 10.5887 - val_loss: 9.6907\n",
      "Epoch 3/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 11.2396 - val_loss: 9.8572\n",
      "Epoch 4/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.5877 - val_loss: 10.5414\n",
      "Epoch 5/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6517 - val_loss: 10.0551\n",
      "Epoch 6/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.7665 - val_loss: 11.7601\n",
      "Epoch 7/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6529 - val_loss: 9.7946\n",
      "Epoch 8/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6452 - val_loss: 9.7874\n",
      "Epoch 9/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6456 - val_loss: 10.2101\n",
      "Epoch 10/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6458 - val_loss: 10.3857\n",
      "Epoch 11/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6249 - val_loss: 11.8128\n",
      "Epoch 12/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6946 - val_loss: 13.0115\n",
      "Epoch 13/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.7270 - val_loss: 13.4121\n",
      "Epoch 14/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.8659 - val_loss: 13.4966\n",
      "Epoch 15/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.7424 - val_loss: 13.1833\n",
      "Epoch 16/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5674 - val_loss: 12.7573\n",
      "Epoch 17/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.5722 - val_loss: 12.9102\n",
      "Epoch 18/100\n",
      "1081/1081 [==============================] - 21s 20ms/step - loss: 10.5236 - val_loss: 9.3396\n",
      "Epoch 19/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4793 - val_loss: 10.4794\n",
      "Epoch 20/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4150 - val_loss: 10.6107\n",
      "Epoch 21/100\n",
      "1081/1081 [==============================] - 19s 18ms/step - loss: 10.4988 - val_loss: 9.4459\n",
      "Epoch 22/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5215 - val_loss: 9.4573\n",
      "Epoch 23/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4851 - val_loss: 9.8025\n",
      "Epoch 24/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6412 - val_loss: 9.8008\n",
      "Epoch 25/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6404 - val_loss: 9.7999\n",
      "Epoch 26/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6400 - val_loss: 9.7999\n",
      "Epoch 27/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6408 - val_loss: 9.7999\n",
      "Epoch 28/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6045 - val_loss: 9.5533\n",
      "Epoch 29/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.4644 - val_loss: 9.8496\n",
      "Epoch 30/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.4224 - val_loss: 10.9396\n",
      "Epoch 31/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.4615 - val_loss: 10.7615\n",
      "Epoch 32/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4415 - val_loss: 11.6658\n",
      "Epoch 33/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4568 - val_loss: 11.2812\n",
      "Epoch 34/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.4930 - val_loss: 12.1200\n",
      "Epoch 35/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5688 - val_loss: 12.1297\n",
      "Epoch 36/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5523 - val_loss: 12.0829\n",
      "Epoch 37/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5268 - val_loss: 12.1299\n",
      "Epoch 38/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5134 - val_loss: 12.1958\n",
      "Epoch 39/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5710 - val_loss: 11.7884\n",
      "Epoch 40/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5237 - val_loss: 11.7721\n",
      "Epoch 41/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.5084 - val_loss: 12.5418\n",
      "Epoch 42/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6636 - val_loss: 11.8367\n",
      "Epoch 43/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6765 - val_loss: 11.8947\n",
      "Epoch 44/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.7258 - val_loss: 10.3282\n",
      "Epoch 45/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6500 - val_loss: 10.1971\n",
      "Epoch 46/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6523 - val_loss: 10.2199\n",
      "Epoch 47/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6499 - val_loss: 10.2522\n",
      "Epoch 48/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6517 - val_loss: 10.3359\n",
      "Epoch 49/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6536 - val_loss: 10.2606\n",
      "Epoch 50/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6496 - val_loss: 10.1658\n",
      "Epoch 51/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6504 - val_loss: 10.2130\n",
      "Epoch 52/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6502 - val_loss: 10.1968\n",
      "Epoch 53/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6477 - val_loss: 9.5313\n",
      "Epoch 54/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6455 - val_loss: 9.5441\n",
      "Epoch 55/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6452 - val_loss: 9.5298\n",
      "Epoch 56/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6456 - val_loss: 9.5439\n",
      "Epoch 57/100\n",
      "1081/1081 [==============================] - 19s 18ms/step - loss: 10.6454 - val_loss: 9.5401\n",
      "Epoch 58/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5594\n",
      "Epoch 59/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5244\n",
      "Epoch 60/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6455 - val_loss: 9.5371\n",
      "Epoch 61/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6456 - val_loss: 9.5443\n",
      "Epoch 62/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6455 - val_loss: 9.5304\n",
      "Epoch 63/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5206\n",
      "Epoch 64/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5398\n",
      "Epoch 65/100\n",
      "1081/1081 [==============================] - 21s 19ms/step - loss: 10.6454 - val_loss: 9.5311\n",
      "Epoch 66/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5432\n",
      "Epoch 67/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5410\n",
      "Epoch 68/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5462\n",
      "Epoch 69/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5228\n",
      "Epoch 70/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5430\n",
      "Epoch 71/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6456 - val_loss: 9.5329\n",
      "Epoch 72/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6453 - val_loss: 9.5409\n",
      "Epoch 73/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5351\n",
      "Epoch 74/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5371\n",
      "Epoch 75/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5322\n",
      "Epoch 76/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6456 - val_loss: 9.5134\n",
      "Epoch 77/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5334\n",
      "Epoch 78/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5437\n",
      "Epoch 79/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5318\n",
      "Epoch 80/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5355\n",
      "Epoch 81/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5141\n",
      "Epoch 82/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6453 - val_loss: 9.5328\n",
      "Epoch 83/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5369\n",
      "Epoch 84/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5415\n",
      "Epoch 85/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5410\n",
      "Epoch 86/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5191\n",
      "Epoch 87/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6457 - val_loss: 9.5334\n",
      "Epoch 88/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5297\n",
      "Epoch 89/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5347\n",
      "Epoch 90/100\n",
      "1081/1081 [==============================] - 19s 18ms/step - loss: 10.6454 - val_loss: 9.5444\n",
      "Epoch 91/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5398\n",
      "Epoch 92/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5334\n",
      "Epoch 93/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6456 - val_loss: 9.5597\n",
      "Epoch 94/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6450 - val_loss: 9.5513\n",
      "Epoch 95/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6456 - val_loss: 9.5328\n",
      "Epoch 96/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6457 - val_loss: 9.5139\n",
      "Epoch 97/100\n",
      "1081/1081 [==============================] - 20s 18ms/step - loss: 10.6454 - val_loss: 9.5185\n",
      "Epoch 98/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5431\n",
      "Epoch 99/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5425\n",
      "Epoch 100/100\n",
      "1081/1081 [==============================] - 20s 19ms/step - loss: 10.6454 - val_loss: 9.5308\n",
      "Elapsed time for training: 2014.51 sec\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "model.fit(X1, Y1, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                     validation_split=0.2, callbacks=callbacks)\n",
    "                     \n",
    "print('Elapsed time for training: %.02f sec' % (time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/model-8Mparameters-100epoch.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-net\n",
    "model.load_weights(filepath = 'model-224.h5')\n",
    "\n",
    "score = model.evaluate(X1, Y1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cidportal.jrc.ec.europa.eu/services/webview/jeodpp/ml-showcase/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "991px",
    "left": "0px",
    "right": "1643px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
