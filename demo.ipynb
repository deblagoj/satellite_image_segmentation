{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from osgeo import gdal\n",
    "from osgeo import gdalconst\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To install gdal\n",
    "conda install -c conda-forge gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadImage(fname, readflag=1):\n",
    "    src = gdal.Open(fname)\n",
    "    projection = src.GetProjection()\n",
    "    geotransform = src.GetGeoTransform()\n",
    "    datatype = src.GetRasterBand(1).DataType\n",
    "    datatype = gdal.GetDataTypeName(datatype)\n",
    "    ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "    lrx = ulx + (src.RasterXSize * xres)\n",
    "    lry = uly + (src.RasterYSize * yres)\n",
    "    cols = src.RasterXSize\n",
    "    rows = src.RasterYSize\n",
    "    Image = 0\n",
    "    if readflag:\n",
    "        Image = src.GetRasterBand(1).ReadAsArray()\n",
    "        print('Image shape: %d %d' % (Image.shape))\n",
    "    print('Spatial resolution: %f %f' % (xres,yres))\n",
    "    return Image, projection, geotransform, (ulx,uly), (lrx,lry), src\n",
    "\n",
    "def Setcmap(D, inv=1):\n",
    "    cmap = plt.cm.jet\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    cmaplist[0] = (.0, .0, .0, 1.0)\n",
    "    if inv:\n",
    "        cmap = LinearSegmentedColormap.from_list('Custom_cmap', cmaplist, cmap.N)\n",
    "    else:\n",
    "        cmap = LinearSegmentedColormap.from_list('Custom_cmap', cmaplist[::-1], cmap.N)\n",
    "    plt.register_cmap(name='Custom_cmap', cmap=cmap)\n",
    "    bounds = np.linspace(0, D, D+1)\n",
    "    norm = BoundaryNorm(bounds, cmap.N)\n",
    "    return cmap, norm\n",
    "    \n",
    "def blockshaped(arr, nrows, ncols):\n",
    "    h, w = arr.shape\n",
    "    return (arr.reshape(h//nrows, nrows, -1, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(-1, nrows, ncols))\n",
    "\n",
    "def unblockshaped(arr, h, w):\n",
    "    n, nrows, ncols = arr.shape\n",
    "    return (arr.reshape(h//nrows, -1, nrows, ncols)\n",
    "               .swapaxes(1,2)\n",
    "               .reshape(h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read S2 bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'S2B_MSIL1C_20181010T104019_N0206_R008_T32ULC_20181010T161145.SAFE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading S2B_MSIL1C_20181010T104019_N0206_R008_T32ULC_20181010T161145.SAFE/GRANULE/L1C_T32ULC_A008328_20181010T104018/IMG_DATA/T32ULC_20181010T104019_B02.jp2\n",
      "Image shape: 10980 10980\n",
      "Spatial resolution: 10.000000 -10.000000\n",
      "Reading S2B_MSIL1C_20181010T104019_N0206_R008_T32ULC_20181010T161145.SAFE/GRANULE/L1C_T32ULC_A008328_20181010T104018/IMG_DATA/T32ULC_20181010T104019_B03.jp2\n",
      "Image shape: 10980 10980\n",
      "Spatial resolution: 10.000000 -10.000000\n",
      "Reading S2B_MSIL1C_20181010T104019_N0206_R008_T32ULC_20181010T161145.SAFE/GRANULE/L1C_T32ULC_A008328_20181010T104018/IMG_DATA/T32ULC_20181010T104019_B04.jp2\n",
      "Image shape: 10980 10980\n",
      "Spatial resolution: 10.000000 -10.000000\n",
      "Reading S2B_MSIL1C_20181010T104019_N0206_R008_T32ULC_20181010T161145.SAFE/GRANULE/L1C_T32ULC_A008328_20181010T104018/IMG_DATA/T32ULC_20181010T104019_B08.jp2\n",
      "Image shape: 10980 10980\n",
      "Spatial resolution: 10.000000 -10.000000\n"
     ]
    }
   ],
   "source": [
    "infolder = os.path.join(folder, 'GRANULE')\n",
    "infolder = os.path.join(infolder, os.listdir(infolder)[0], 'IMG_DATA')\n",
    "infile = os.path.join(infolder, fnmatch.filter(os.listdir(infolder), '*B02.jp2')[0])\n",
    "print('Reading '+infile)\n",
    "Blue, PROJ, GEOTR, p1, p2, SRC = ReadImage(infile)\n",
    "rows, cols = SRC.RasterYSize, SRC.RasterXSize\n",
    "infile = os.path.join(infolder, fnmatch.filter(os.listdir(infolder), '*B03.jp2')[0])\n",
    "print('Reading '+infile)\n",
    "Green, _, _, _, _, _ = ReadImage(infile)\n",
    "infile = os.path.join(infolder, fnmatch.filter(os.listdir(infolder), '*B04.jp2')[0])\n",
    "print('Reading '+infile)\n",
    "Red, _, _, _, _, _ = ReadImage(infile)\n",
    "infile = os.path.join(infolder, fnmatch.filter(os.listdir(infolder), '*B08.jp2')[0])\n",
    "print('Reading '+infile)\n",
    "NIR, _, _, _, _, _ = ReadImage(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2025, 244, 244)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 244\n",
    "A = blockshaped(Blue, window, window)\n",
    "Stack = np.expand_dims(A, axis=0)\n",
    "A = blockshaped(Green, window, window)\n",
    "Stack = np.concatenate((Stack, np.expand_dims(A, axis=0)), axis=0)\n",
    "A = blockshaped(Red, window, window)\n",
    "Stack = np.concatenate((Stack, np.expand_dims(A, axis=0)), axis=0)\n",
    "A = blockshaped(NIR, window, window)\n",
    "Stack = np.concatenate((Stack, np.expand_dims(A, axis=0)), axis=0)\n",
    "del A, Blue, Green, Red, NIR\n",
    "Stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.float32(Stack)\n",
    "X[X>10000] = 10000\n",
    "X = X / 10000.\n",
    "X = np.rollaxis(X, 0, 4)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,:128,:128,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_params = np.load('std_params.npy')\n",
    "mu = std_params[0,:]\n",
    "std = std_params[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(X.shape[3]):\n",
    "    tmp = np.copy(X[:, :, :, q])\n",
    "    tmp = tmp.flatten()\n",
    "    print(mu[q], std[q])\n",
    "    tmp[tmp>0] = (tmp[tmp>0] - mu[q]) / std[q]\n",
    "    X[:, :, :, q] = tmp.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    del tmp\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## U-net\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.layers import merge, Conv2D, MaxPooling2D, UpSampling2D, Reshape, core, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "img_size=(128, 128, 4)\n",
    "num_classes = 9\n",
    "\n",
    "def unet(img_size, num_classes):\n",
    "    inputs = keras.Input(shape=img_size )\n",
    "\n",
    "    ### [First half of the network: downsampling inputs] ###\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Conv2D(32, 3, strides=2,  padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    # Blocks 1, 2, 3 are identical apart from the feature depth.\n",
    "    for filters in [64, 128, 256]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(filters, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    ### [Second half of the network: upsampling inputs] ###\n",
    "\n",
    "    for filters in [256, 128, 64, 32]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2DTranspose(filters, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.UpSampling2D(2)(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.UpSampling2D(2)(previous_block_activation)\n",
    "        residual = layers.Conv2D(filters, 1, padding=\"same\")(residual)\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    # Add a per-pixel classification layer\n",
    "    outputs = layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = unet(img_size, num_classes)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 4)\n",
    "model = unet(input_shape,9)\n",
    "model.summary()\n",
    "batch_size = 25\n",
    "fnmodel = 'model.h5'\n",
    "model.load_weights(filepath = fnmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resp = model.predict(X, batch_size=3*batch_size).argmax(axis=-1)\n",
    "Class = unblockshaped(Resp, 5760, 5760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap, norm = Setcmap(9)\n",
    "im = plt.imshow(Class, cmap=cmap, norm=norm, vmin=0, vmax=9)\n",
    "plt.title('Classification')\n",
    "plt.set_cmap(cmap)\n",
    "cb = plt.colorbar(im, fraction=0.046, pad=0.04, ticks=range(9))\n",
    "cb.set_ticks(np.arange(9) + .5)\n",
    "cb.set_ticklabels(np.arange(9))\n",
    "plt.gcf().set_size_inches(15, 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
